{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Deyht/ML_OSAE_M2/blob/ML_OSAE_M2/codes/CNN/ASIRRA_TensorFlow.ipynb)"
      ],
      "metadata": {
        "id": "TSGpthJPGaAy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO6gdziDA3BZ",
        "outputId": "513d4eba-e060-4260-a482-8f8cf6a235d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-27 11:45:57--  https://share.obspm.fr/s/jqGotokdYDXTbDS/download/data_asirra.tar.gz\n",
            "Resolving share.obspm.fr (share.obspm.fr)... 145.238.186.112\n",
            "Connecting to share.obspm.fr (share.obspm.fr)|145.238.186.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 820207429 (782M) [application/gzip]\n",
            "Saving to: ‘data_asirra.tar.gz’\n",
            "\n",
            "data_asirra.tar.gz   95%[==================> ] 750.66M  26.5MB/s    eta 2s     "
          ]
        }
      ],
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/\n",
        "\n",
        "wget https://share.obspm.fr/s/jqGotokdYDXTbDS/download/data_asirra.tar.gz\n",
        "\n",
        "tar -xzf data_asirra.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def make_square(im, min_size=128, fill_color=(0, 0, 0, 0)):\n",
        "    x, y = im.size\n",
        "    size = max(min_size, x, y)\n",
        "    new_im = Image.new('RGB', (size, size), fill_color)\n",
        "    new_im.paste(im, (int((size - x) / 2), int((size - y) / 2)))\n",
        "    return new_im\n",
        "\n",
        "\n",
        "def zoom_at(img, x, y, zoom):\n",
        "    w, h = img.size\n",
        "    zoom2 = zoom*2\n",
        "    img = img.crop((x - w / zoom2, y - h / zoom2,\n",
        "                    x + w / zoom2, y + h / zoom2))\n",
        "    return img.resize((w, h), Image.LANCZOS)\n",
        "\n",
        "def roll_zeropad(a, shift, axis=None):\n",
        "    a = np.asanyarray(a)\n",
        "    if shift == 0: return a\n",
        "    if axis is None:\n",
        "        n = a.size\n",
        "        reshape = True\n",
        "    else:\n",
        "        n = a.shape[axis]\n",
        "        reshape = False\n",
        "    if np.abs(shift) > n:\n",
        "        res = np.zeros_like(a)\n",
        "    elif shift < 0:\n",
        "        shift += n\n",
        "        zeros = np.zeros_like(a.take(np.arange(n-shift), axis))\n",
        "        res = np.concatenate((a.take(np.arange(n-shift,n), axis), zeros), axis)\n",
        "    else:\n",
        "        zeros = np.zeros_like(a.take(np.arange(n-shift,n), axis))\n",
        "        res = np.concatenate((zeros, a.take(np.arange(n-shift), axis)), axis)\n",
        "    if reshape:\n",
        "        return res.reshape(a.shape)\n",
        "    else:\n",
        "        return res\n",
        "\n",
        "\n",
        "def im_transform(im):\n",
        "\tim2 = im.copy()\n",
        "\tif(np.random.randint(0,2)):\n",
        "\t\tim2 = ImageOps.mirror(im2)\n",
        "\tim2 = im2.transform(im2.size, Image.AFFINE, (1.0-0.2*np.random.rand(),0.0, (np.random.rand()*2.0-1.0)*(im2.size[0]*0.1),\n",
        "\t\t0.0,1.0-0.2*np.random.rand(), (np.random.rand()*2.0-1.0)*(im2.size[1]*0.1)))\n",
        "\t#im2 = im2.rotate(np.random.rand()*40.0-20.0)\n",
        "\tim2 = im2.resize((128,128))\n",
        "\n",
        "\treturn im2\n",
        "\n",
        "orig_nb_images = 11500\n",
        "test_size = 1000\n",
        "image_size = 128\n",
        "augm_fact = 2\n",
        "\n",
        "train_im = np.zeros((orig_nb_images*augm_fact*2,image_size,image_size,3), dtype=\"uint8\")\n",
        "\n",
        "for i in tqdm(range(0, orig_nb_images)):\n",
        "\tim = Image.open(\"/content/data/PetImages/Cat/\"+str(i)+\".jpg\")\n",
        "\twidth, height = im.size\n",
        "\n",
        "\tim = make_square(im)\n",
        "\twidth2, height2 = im.size\n",
        "\n",
        "\tx_offset = int((width2 - width)*0.5)\n",
        "\ty_offset = int((height2 - height)*0.5)\n",
        "\n",
        "\tim = im.resize((image_size,image_size))\n",
        "\n",
        "\tfor k in range(0,augm_fact):\n",
        "\t\tim_array = np.asarray(im_transform(im))\n",
        "\t\ttrain_im[i*augm_fact+k,:,:,:] = im_array[:,:,:]\n",
        "\n",
        "for i in tqdm(range(0,orig_nb_images)):\n",
        "\tim = Image.open(\"/content/data/PetImages/Dog/\"+str(i)+\".jpg\")\n",
        "\twidth, height = im.size\n",
        "\n",
        "\tim = make_square(im)\n",
        "\twidth2, height2 = im.size\n",
        "\n",
        "\tx_offset = int((width2 - width)*0.5)\n",
        "\ty_offset = int((height2 - height)*0.5)\n",
        "\n",
        "\tim = im.resize((image_size,image_size))\n",
        "\n",
        "\tfor k in range(0,augm_fact):\n",
        "\t\tim_array = np.asarray(im_transform(im))\n",
        "\t\ttrain_im[orig_nb_images*augm_fact+i*augm_fact+k,:,:,:] = im_array[:,:,:]\n",
        "\n",
        "train_im.tofile(\"train_im.dat\")\n",
        "\n",
        "del (train_im)\n",
        "\n",
        "test_im = np.zeros((test_size*2,image_size, image_size,3), dtype=\"uint8\")\n",
        "\n",
        "for i in tqdm(range(0, test_size)):\n",
        "\tim = Image.open(\"/content/data/PetImages/Cat/\"+str(orig_nb_images+i)+\".jpg\")\n",
        "\twidth, height = im.size\n",
        "\n",
        "\tim = make_square(im)\n",
        "\twidth2, height2 = im.size\n",
        "\n",
        "\tx_offset = int((width2 - width)*0.5)\n",
        "\ty_offset = int((height2 - height)*0.5)\n",
        "\n",
        "\tim = im.resize((image_size,image_size))\n",
        "\n",
        "\tim_array = np.asarray((im))\n",
        "\ttest_im[i,:,:,:] = im_array[:,:,:]\n",
        "\n",
        "for i in tqdm(range(0,test_size)):\n",
        "\tim = Image.open(\"/content/data/PetImages/Dog/\"+str(orig_nb_images+i)+\".jpg\")\n",
        "\twidth, height = im.size\n",
        "\n",
        "\tim = make_square(im)\n",
        "\twidth2, height2 = im.size\n",
        "\n",
        "\tx_offset = int((width2 - width)*0.5)\n",
        "\ty_offset = int((height2 - height)*0.5)\n",
        "\n",
        "\tim = im.resize((image_size,image_size))\n",
        "\n",
        "\tim_array = np.asarray((im))\n",
        "\ttest_im[test_size+i,:, :,:] = im_array[:,:,:]\n",
        "\n",
        "\n",
        "test_im.tofile(\"test_im.dat\")\n",
        "\n",
        "del (test_im)"
      ],
      "metadata": {
        "id": "j2NH5rue7vbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "image_size = 128\n",
        "nb_per_class = 11500\n",
        "nb_test = 1000\n",
        "augm_fact = 2\n",
        "train_data = np.fromfile(\"train_im.dat\", dtype=\"uint8\")\n",
        "train_data = np.reshape(train_data, ((nb_per_class*2*augm_fact,image_size,image_size,3)))\n",
        "\n",
        "train_targets = np.zeros((nb_per_class*2*augm_fact,2), dtype=\"float32\")\n",
        "\n",
        "#train_data[:] /= 255.0\n",
        "\n",
        "train_targets[0:nb_per_class*augm_fact,0] = 1.0\n",
        "train_targets[nb_per_class*augm_fact:,1]  = 1.0\n",
        "\n",
        "test_data = np.fromfile(\"test_im.dat\", dtype=\"uint8\")\n",
        "test_data = np.reshape(test_data, ((nb_test*2,image_size,image_size,3)))\n",
        "\n",
        "test_targets = np.zeros((nb_test*2,2), dtype=\"float32\")\n",
        "\n",
        "#test_data[:] /= 255.0\n",
        "\n",
        "test_targets[0:nb_test,0] = 1.0\n",
        "test_targets[nb_test:,1]  = 1.0\n",
        "\n"
      ],
      "metadata": {
        "id": "0T4_3ajxCrpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "######################### ##########################\n",
        "#         Loading the neural network model\n",
        "######################### ##########################\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.ZeroPadding2D(padding=(1, 1), input_shape=(image_size,image_size,3)))\n",
        "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D())\n",
        "\n",
        "model.add(layers.ZeroPadding2D(padding=(1, 1)))\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D())\n",
        "\n",
        "model.add(layers.ZeroPadding2D(padding=(1, 1)))\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D())\n",
        "\n",
        "model.add(layers.ZeroPadding2D(padding=(1, 1)))\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D())\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(units=512, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(units=2, activation = 'softmax'))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "######################### ##########################\n",
        "#                 Network training\n",
        "######################### ##########################\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(train_data, train_targets, batch_size=32, epochs=40, shuffle=True,  validation_split=0.0, validation_data=(test_data, test_targets))\n",
        "\n",
        "######################### ##########################\n",
        "#            Evaluate the network prediction\n",
        "######################### ##########################\n",
        "\n",
        "model.evaluate(test_data, test_targets)\n",
        "\n",
        "pred = model.predict(test_data)\n",
        "\n",
        "matrix = metrics.confusion_matrix(test_targets.argmax(axis=1), pred.argmax(axis=1))\n",
        "\n",
        "print (matrix)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PclrAI6JwJ-m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}